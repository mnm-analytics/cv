業務経歴書
===

## ｜ 基本情報

| key    | value                                                                                      |
|:------ |:------------------------------------------------------------------------------------------ |
| 名前   | 西村 圭介                                                                                  |
| tel   | 090.8262.5618                                                                        |
| mail   | ksksk0709@gmail.com                                                                        |
| 検定   | 統計検定 準1級                                                                             |
| 語学力 | TOEIC 810点                                                                                |
| IQ     | FIQURE 148 (sd 15) 　[高IQ団体 PercentOne](https://www.facebook.com/iqover135/)所属|
| 連載   | [「AI」エンジニアになるための「基礎数学」再入門](https://www.itmedia.co.jp/author/220138/) |

<!-- | ポートフォリオ | xxx| -->

## ｜ 概要

- 現在の専門は次の通り。
    - ビジネス課題設定・仮説立案
    - データ取得（設計、スクレイピング）
    - 分析設計
    - 統計・機械学習
    - 機械学習モデル運用
- 多種多様な言語/DB/ライブラリー/フレームワークを用いた豊富な開発経験あり。
- AWS/GCPなどのマネージドサービスについても実務において十分な使用経験あり。
- PDCAの早い、迅速なアウトプットが求められるような現場において非常に有用なエンジニアであると自負している。
- マシンパワーやデータ量に逃げることなく、真に価値あるアウトプットを提出することをモットーとしている。
- サービスのローンチ前など取得データ設計の段階から参画させて頂くことで最もバリューを発揮できる。
- 「手を動かす」業務はもちろんのこと、「ビジネスコンサル」「分析技術コンサル」「技術顧問」まで幅広く対応可能。
- 専門外ではあるがWEBアプリケーション/APIの開発経験もあり。

## ｜ スキル

- 全て実業務で使用したものだけ列挙する。

### 言語

`Python` `SAS` `R` `Julia` `Scala` `Java`  `JavaScript` `Ruby` `PHP` `C`

### ライブラリー

`numpy` `pandas` `matplotlib` `seaborn` `sklearn` `scipy` `xgboost` `lightgbm` `tensorflow` `keras` `pytorch` `Mahout` `Spark Mlib`

### フレームワーク

`Struts` `Flask` `Django` `jQuery` `.NET Framework` `react.js` `vue.js`

### RDB/NoSQL

`MySQL` `PostgreSQL` `Oracle` `SQL Server` `HiveQL`

### クラウド

##### AWS

`S3` `API Gateway` `Lambda` `EC2` `Cloud9` `Elasticsearch Service` `RDS(MySQL|PostgreSQL)` `Redshift` `EMR(Spark)` `Amazon Translate`

##### GCP

`BigQuery` `GCS` `Cloud Functions` `GCE` `Cloud SQL` `ML Engine`

### SaaS/PaaS

`GitHub` `TreasureData`

### その他

`Docker` `Mecab` `Cabocha` `TreeTagger` `Hadoop`

## ｜ バリューを発揮しやすい案件
- レコメンド
- Web解析
- 時系列モデリング
- 異常検知
- 因果推論
- KGI-KPIツリー設計・ダッシュボード作成
- 研修講師（AI概要./python/統計学/機械学習）

## ｜ 主な業務経歴(時期降順)

### デジマ支援(2021年~)

`BigQuery` `SAS` `GA` `adjust`

【プロジェクト概要】
- 国内最大手のキャリアをクライアントとして、決済サービスのMAU目標達成を支援。
- 成果は次の通り。
    - MAUの年度目標達成
    - PUSH施策での事故・クレーム無し
    - 週次での経営層報告に提出する分析結果の提出遅延無し

【担当業務】
- オウンド/ペイドメディアでの施策のPDCAを週単位でまわす。
- 社内システム/ツールのフィジビリ調査や、使用にあたっての社内調整をリードする。

【発揮したバリュー】
- 施策実施をスケジュール通りに滞りなく遂行。
    - 使用予定ツールを高速にキャッチアップすることにより社内調整完了までの期間を短縮。
- 施策仕様の具体化を緻密に行い、PUSH施策での事故・クレームの予防に繋げた。
- リソースマネジメントと効率的な開発で、分析結果の提出遅延予防に繋げた。

### ペイド広告費用最適化(2021年~)
`cURL` `Python` `selenium` `beautiful soup` `adjust` `googleAPI` `appleAPI` `facebookAPI` `twitterAPI` `その他媒体API`

【プロジェクト概要】
- 国内屈指のゲーム会社で、国民的IPを保有していることが強みのクライアント。
- 複数媒体で広告を打っているが効果測定ができておらず、RoIが最適化されていない。
- 各媒体のRoIを可視化するために、システマチックにデータ収集・蓄積しデータ統合するタスクを担った。

【担当業務】
- リサーチャー：各APIの仕様調査やアカウント/権限の手配
- プログラマー：データ取得/スクレイピング用のバッチ開発

【発揮したバリュー】
- リサーチ力：突破困難なgoogle認証を、driver仕様/ブラウザ仕様の調査を行うことで突破した。

### ソシャゲ チートユーザー検知(2021年~)
`Python` `EllipticEnvelope` `1 class SVM` `Isolation Forest` `RandomCutForest`

【プロジェクト概要】
- 国内屈指のゲーム会社で、国民的IPを保有していることが強みのクライアント。
- あるゲームタイトルにてチートユーザーの発生とその管理が課題とされており、異常ユーザーの抽出を目的とした。
- 精度はACC=99.3%

【担当業務】
- コンサルタント/サイエンティスト/エンジニアとほぼ全領域を担当。
- データクレンジング～モデリング・検証～集計・運用体制構築など一連の工程を担当。

【発揮したバリュー】
- ビジネスインパクト最大化に集中することで、実業務で使い続けられるシステムに仕上げることができた。
    - 精度にこだわる時間を最小限にした。
    - 現場からの理解・信用を獲得するために頻繁にヒアリング・説明会を開催。
        - 極力解釈性のあるアルゴリズムを採用。
        - 現場の声を取り入れて納得性のある特徴量を作成。

### ゲームのライフサイクル予測(2020年~)

`Python` `ARIMA` `VARモデル`

【プロジェクト概要】
- 国内屈指のゲーム会社で、国民的IPを保有していることが強みのクライアント。
- ソーシャルゲームを複数タイトル運用しているが、今後どのタイトルに注力したらよいか見極めたいという要望。
- 精度は次の通り。
    - 新規ユーザー数予測：シグモイド関数のfitにてMAPE=0.13。
    - 復帰ユーザー数予測：VARモデルにてMAPE=0.18。

【担当業務】
- コンサルタント/サイエンティスト/エンジニアとほぼ全領域を担当。具体的には下記。
    - 全タイトルの今後半年間の新規/復帰ユーザー数を予測し、その値の大小でアロケーションするという方針を設計・提案。
    - データクレンジング～モデリング・検証～集計など一連の工程を実装。

【発揮したバリュー】
- 当初はARIMAモデルで予測する予定だったが、全20タイトルとモデリング回数も多いことから工数が大きく、また精度も芳しくなかった。そこで、基本的なゲームの新規ユーザー数にsigmoid関数がよくfitすることに着目・提案し、大幅に工数削減・精度向上させることができた。

### ゲームのローカライズに際する誤翻訳検知(2019年~)

`Python` `flask` `docker` `TreeTagger` `MeCab` `AWS Traslate` `Google Translate` `lightgbm`

【プロジェクト概要】
- 国内屈指のゲーム会社で、国民的IPを保有していることが強みのクライアント。
- 国内のみならず海外売上の規模も大きく、自然な言葉かつ現地の文化と親和性のある表現で翻訳する必要があるが、誤翻訳が度々起こることに課題を抱えている。
- lightgbmにてAUC=0.81。

【担当業務】
- コンサルタント/サイエンティスト/エンジニアとほぼ全領域を担当。具体的には下記。
    - 過去の日本語原文とローカライザー翻訳文を参考に、品詞の頻度の違いや文法間違いから誤翻訳を検知できると設計・提案。
    - 文章クレンジングの方針やタグ付けライブラリーの選定および設定の指定を行い厳密に品詞頻度を比較できるように分析を設計。
    - データクレンジング～加工～タグ付け～集計など一連の工程を実装。

【発揮したバリュー】
- 単純に和文・英文の品詞頻度を比較しても相違がでて当然なので、AWSやGCPの翻訳APIで相互に翻訳し、それぞれの言語の原文と品詞頻度を比較するという提案を行い合意を得たことで、プロジェクトの前進に貢献した。
- APIの精度が完ぺきではないことに注目し、上手く誤翻訳検知できるできるようにドメイン知識を活かしたに単語量・熟語帳を作成したことで、精度向上に貢献した。
- スケジュールがタイトな案件だったこともあり、開発～デプロイに労力をかけないゆおうにdockerを用いることを提案し合意を得た。それにより、スケジュールに余裕を持たせ、なおかつ本番環境でのエラーもなく、滞りなく納品した。
- 実運用の際はAPIを使用することを提案し、applicationAPI/clientAPIの構築と一貫して全ての構築作業を手掛けた。

### 家庭用ゲームの販売本数に関する因果推論(2019年)

`Python` `BigQuery`

【プロジェクト概要】
- 国内屈指のゲーム会社で、国民的IPを保有していることが強みのクライアント。
- 家庭用ゲームの販売本数とプロモーション施策の因果を知ることで、プロモーションの経費を最適化したいという要望。

【担当業務】
- サイエンティスト/エンジニアを担当。具体的には以下。
    - 手元のデータから生成できる特徴量を明示化し、各特徴量に関してどのような分析・検定を行うか明示的に設計。
    - 手元のデータから特徴量を抽出しマート生成。
    - VARモデルでのモデリング。
    - 精度・影響力報告用の資料作成。

【発揮したバリュー】
- 人の手垢がこびりついた非常に汚いデータだったが、根気よくマーケターとコミュニケーションをとり、異常値と外れ値の排除を行ったことで、モデルの妥当性・精度の向上に貢献した。
- 交絡因子が大いにあると思われたために、twitterなどで情報を地道に集め、フラグ作成をすることで、精度向上やモデルの納得性向上に貢献した。

### 5G CoreNetWork APIのR&D(2019年)

`Python` `flask` `Swagger` `OpenAPI`

【プロジェクト概要】
- メーカー系の国民的大企業で日本屈指の信用に強みをもつクライアント。
- 来る5G時代に向けて、商品・サービス開発において先手を打つべく、5GC APIの仕様理解および商品・サービス開発にとって重要なAPIのモックを作成してほしいとの要望。

【担当業務】
- リサーチャー/エンジニアを担当。具体的には以下。
    - API仕様書を読み込み要約・資料化し、重要なAPIの提案。
    - 重要なAPIを仕様通りにflaskで再現し、どのようなレスポンスが返ってくるかを明確化。

【発揮したバリュー】
- 週次定例があり、クイックなアウトプットが必要とされる状況かつ膨大な英仕様書を読み込むというシビアな状況であったが、持ち前のリテラシー・読解力・資料作成能力を発揮し、重要APIの提言し合意を得ることで、プロジェクトの前進に貢献した。

### 金融商材の購入に関する因果推論(2019年)

`Python` `Ruby` `Hadoop`

【プロジェクト概要】
- メーカー系の国民的大企業で日本屈指の信用に強みをもつクライアント。
- 金融商材のマーケ施策を効率的に行うためにWEB上の行動量やデモグラ情報と成約の因果関係を科学的に解析したいという要望。

【担当業務】
- コンサルタント/サイエンティスト/エンジニアの領域を担当。具体的には下記。
    - 必要なデータを定義し、取得可能なデータを洗い出した上で、できることの範囲を明示し、プロジェクトのゴールを明確化。
    - 必要最小限の変数で最大限の精度を発揮するモデルを構築するため、各変数に対してどのような検定を行い、結果に応じてどのような判断を行うかを明確化するように設計。
    - 各種データ取得・加工の一部も担当。

【発揮したバリュー】
- 居住都道府県ごとの成約率の群間分散が大きいことに注目し、さらなる深掘りとして空間統計学のMoranのI統計量を確認し、隣接地域も成約率に相関があることを提言し、モデルの精度向上や納得性向上に貢献した。
- 隣接都道府県を特徴量に組み込む際に隣接行列の概念を応用し、効率的に実装し、工数削減やプロジェクトの前進に貢献した。
- 「CMの内容と日本の各地域の生活スタイルを掛け合わせ場合に考えられるリーチされる側の受け取り方」など、深いドメイン知識を特徴量に組み込むことで、モデルの精度向上や納得性向上に貢献した。
- サンプルサイズを考慮せず安易にカイ二乗検定をしていようとしている場面を発見し、統計量がカイ二乗分布に従わない（近似できない）ことを指摘。そこでフィッシャーの直接確率のアルゴリズムを実装し、分析の妥当性を高めることに貢献した。

### 研修講師(2018年~)
`Python` `機械学習` `統計学` `keras`

【プロジェクト概要】
- 都内最大規模のIT研修事業をもつクライアント。
    - 既存顧客数や高リピート率に強みをもつ。
- Java・SQL・WEBフレームワークなど一般的な技術研修を行ってきたが、新たにPyhtonや機械学習の研修もやりたいという要望。

【担当業務】
- カリキュラム作成/資料作成/講師/技術営業とほぼ関わる全領域を担当。詳しくは以下。
    - 社会のニーズと合致するような達成目標を定め、目標を満たせるようなカリキュラムを制定。
    - カリキュラムごとの資料作成およびeラーニング用教材も作成。
    - 集客用セミナーや集合型研修では講師を担当。
    - 営業に同行し、ヒアリング・提案を技術側の意見で行う。

【発揮したバリュー】
- 集客セミナーや技術営業で顧客獲得を手伝っており、累計約700名の受講者を獲得することに貢献。（2020.03 現在）
- 資料作成能力と説明能力に長けており、技術的かつある程度難解な研修もやる中で、アンケートにて研修全体の分かり易さ平均4.6、講師の説明の分かり易さ平均4.8(5段階評価)と高評価を頂いており、マーケティング面やリピート獲得に大きく貢献している。
- 研修カリキュラムの中にある補習の中で、受講者の実務上での課題についてコンサルティングもしている。企画の通し方のレクチャー・分析設計の指南・分析手法の提案・分析環境や人員構成の提案など幅広くサポートしており、顧客満足度やリピート率の向上に貢献している。

### ECサイトの会員獲得クーポン配布リスティング(2018年)

`Python` `lightgbm`

【プロジェクト概要】
- 膨大な総ID数とグループ内にDSPシステムを保有していることが特徴のクライアント。
- 新規ID獲得のためのクーポンをDSPを用いて配布したいが、広告1表示ごとに料金がかかるため、CPAを一定に抑えてトータルの経費を最小限に抑えたいという要望。
- lightgbmにてAUC=0.88。

【担当業務】
- サイエンティスト/エンジニアの領域を担当。具体的には下記。
    - 他サービスや過去施策のデータから、特徴量を量産。
    - 教師あり学習でDSP配信した場合に入会するか否かの分類モデリング。
    - モデルが出力するprobabilityから、閾値ごとの予想CPA・トータル経費を算出した結果をもとに閾値を提案。

【発揮したバリュー】
- 人脈作りが得意で、それを活かし他の技術者と積極的にコミュニケーションし、大量のドメイン知識を入手したことで、多くの特徴量を生成した。
    - 副次的だが、ここで生成したマートを使用して他の当てもの案件も成功したので、現場内のチームで横断的に使用されるようになり、組織全体の生産性向上に貢献した。
- lightgbmの扱いを深く理解していたため、専門的なモデリングテクニック（Kaggler御用達ではあるが、アンサンブルやスタッキングなど）を駆使し、最終的にはAUC=0.88と高性能なモデルを生成。クライアントの要望に大いに応えた。
    - 経費は全送信の50%を抑え、推定90%の入会者を刈り取った。

### ECサイトの施策立案&効果検証(2017年)

`Python` `TreasureData` `Redshift`

【プロジェクト概要】
- ECサイトの活性化のためにクイックに施策立案・効果検証を繰り返す必要があるクライアント。
- 週次定例で分析結果を報告し、施策立案を行う必要があるというリソース的にシビアなプロジェクト。

【担当業務】
- コンサルタント/アナリストを担当。具体的には下記。
    - 顧客のセグメンテーション。
    - 施策の効果検証・報告資料作成。
    - 効果検証結果をもとに新施策の提案。

【発揮したバリュー】
- 分析においては、あらゆる角度からRoI（継続顧客/円、新規顧客/円、売上リフト/円など）を算出し、無駄打ち施策を淘汰することで経費削減に貢献した。
- 資料作成においては、工数を最小限にするために、パワポではなくmarkdownでのスライド作成をチームにレクチャーし、リソース的にシビアながらもヘルシーなチームへと変革することに貢献した。
- 多数のECサイトの利用や書籍の読み込みで、貪欲にドメイン知識を獲得し、的確な施策立案を行うことで、意思決定および利益向上に貢献した。

### 横断レコメンドシステムのR&D(2017年)

`Python` `word2vec` `Spark`

【プロジェクト概要】
- 複数ECサイトを持つクライアント。
- 相互送客を促進するためにサイトAの商品をサイトBにレコメンドしたいという要望。
- サイトAとサイトBの共通IDが少量のため、一般的な教師あり学習や協調フィルタリングが適用し難い状況。
- R&D案件だったため、実用性に加えて、新規性や話題性も重視されるような案件。

【担当業務】
- リサーチャー/サイエンティストの領域を主に担当。具体的には下記。
    - word2vecを応用したitem2vecを用いてレコメンドする企画を提案。
    - 生成した商品ベクトルがレコメンドにとって有用であるかのPoC。
        - 商品ベクトルが商品の性質（カテゴリやターゲット層）を表現しているかの確認。
        - 複数サイトの商品ベクトルを同じ線形空間へ写像した際に、類似商品が近い距離にあるか確認。
- 言語は`Python`、分析基盤は`EMR(Spark)`。

【発揮したバリュー】
- レコメンドの実証実験ができない状況だったので、商品ベクトルの有用性を主張することが難しい状況であったが、クラスター分析や次元削減系のアルゴリズム（主成分・Tsne）を利用することで、結果の解釈性や説得性を高めることに成功し、ベクトルの有用性を証明することに貢献した。
- word2vecはハイパーパラメーターの決定が難しいアルゴリズムだが、多数の論文から総合的に判断・報告し、プロジェクトの進行に貢献した。
- 「商品ベクトルの類似度を算出する際にユークリッド距離よりもコサイン距離の方が適しているのではないか」という仮説があがった際、Rが容易に使用できない状況だったために実装の困難に陥った。そこでは持ち前の数学力で、「全てのベクトルを単位ベクトルに規格化した後にユークリッド距離を算出することで実質コサイン距離を算出していることになること」を発案・実装し、プロジェクトの前進に貢献した。

### レコメンドエンジンの開発・精度向上(2017年)

`Scala` `Spark` `協調フィルタリング` `AWS` `Python` `トピックモデル`

【プロジェクト概要】
- 膨大な総ID数とオムニチャネルに強みをもつクライアント。
- ECサイトのレコメンドエンジンの開発および精度向上を担当。
    - ランキング vs レコメンドv1 => CVR 1.3 倍を記録。
- 精度向上では自然言語解析を用いたコールドスタート問題に対応。
- コールドスタート対策では、商品の説明文に対してトピックモデルを用いて商品の抽象化することで対応。
    - レコメンドv1 vs レコメンドv2 => CVR 1.2 倍を記録。
- v2のリリースにて、年間売上として約2億円の押上げ効果を発揮。

【担当業務】
- リサーチャー/サイエンティスト/エンジニア/運用の全領域を担当。具体的には下記。
    - 実現可能性、最適アルゴリズム、最適ライブラリーの調査および選定。
    - インフラ設計や、アプリケーションのアーキテクチャの設計作業。
    - 各種実装/テスト。
    - 運用時の障害対応および精度レポーティング。
- 言語は`Scala` `Python`、分析基盤は`EMR(Spark)`。

【発揮したバリュー】
- `Scala`に関しては「Better Java」ではなく「関数型スタイルでの開発」が徹底されている環境だったため、概念に慣れるまで非常に苦労したが、「Scala関数型デザイン＆プログラミング」等で学習し短時間でキャッチアップ。
- 非常に大きなサイズのアクセスログや購買ログを使用していたため、`Spark`に関しては独特の遅延評価やインメモリ処理とリソースとの兼ね合いに非常に苦労した。ここでも短期間でSparkの仕様を精緻に学習したことで、システムの保守性と処理速度の大幅な向上に貢献した。
- ABテスト用のデータ集めの際は、無駄打ちが増えないように、都度サンプルサイズ設計をする運用を行うことで、テストにおける経費を最小限に留めた。
- 自然言語解析においては、効率的にデータ加工～モデリング～可視化を行えるようにスクリプトを組み、クイックに集計・議論を繰り返せる環境を整えたことで、十分にドメイン知識を取り入れた納得性のある処理を実現することに貢献した。



<!--

### 研修講師(2018~年)


-->
